import Box from "@mui/material/Box";
import Typography from "@mui/material/Typography";
import Link from "@mui/material/Link";
import ReactMarkdown from "react-markdown";
import LaTeX from "@site/src/components/LaTeX/LaTeX";

<Typography variant="body2">
  G-Eval is an evaluation framework that utilizes a large language model (LLM),
  such as a variant of GPT, as an automated judge to assess the quality of
  generated text. Unlike traditional metrics that rely on lexical or semantic
  overlap with a reference, G-Eval evaluates text based on a set of user-defined
  criteria and scoring rubrics provided within a carefully crafted prompt.
</Typography>

<Typography variant="body2">
  The original formulation of G-Eval proposed a two-step process consisting of
  generating a detailed prompt based on high-level evaluation criteria and using
  this prompt to evaluate the text. However, it is typically recommended to
  perform the first step in advance of the evaluation and fix the obtained
  prompt for better reproducibility.
</Typography>

<Typography variant="body2" gutterBottom>
  G-Eval can operate with or without a reference text. When a reference is
  provided, the evaluation criteria may directly refer to this text. Without a
  reference, it is possible to evaluate general aspects of the output, such as
  output fluency and conciseness, or to assess its correctness with respect to
  some background information or context included in the prompt. While high
  flexibility makes G-Eval applicable to a wide range of tasks, it is highly
  sensitive to the performance of the LLM judge and may also be influenced by
  the quality of the prompt. Prior research has also shown that G-Eval tends to
  assign higher scores to LLM-generated text compared to text written by humans,
  sometimes even in cases when the human-written text is of comparable or higher
  quality.
</Typography>

<Typography variant="subtitle1" gutterBottom>
  Evaluation Process
</Typography>

<Typography variant="body2">
1. **Evaluation Criteria Definition**
    - The user specifies the high-level criteria that should be used to evaluate
    a certain quality of the generated text and a scoring scale to use for this
    evaluation.
1. **Prompt Construction**
    - The evaluation criteria can be passed to an LLM to generate a more detailed
    prompt including precise instructions and a scoring model. Alternatively, it
    is possible to define this prompt manually. The final prompt template should
    also specify any inputs to the evaluation, such as the generated text to be
    evaluated, the reference text (if available) or any additional contextual information.
1. **LLM Evaluation**
    - An LLM judge is asked to assign a numerical score to the generated text based
    on the instructions provided in the prompt. To reduce variance and effects of
    randomness, it is typically recommended to compute this score using a weighted
    average of scores according to the token probabilities outputted by the LLM,
    if available.

</Typography>

<Typography variant="subtitle1" gutterBottom>
  Example G-Eval Prompt
</Typography>

<Typography variant="body2" component="div" >
Below is an example of a G-Eval prompt that could be used for evaluating correctness/faithfulness of a medical note generated from a doctor-patient dialogue.

<Box style={{fontStyle: "italic"}}>
You are a medical expert tasked with evaluating the faithfulness of a clinical note generated by a model from doctor-patient dialogue. You will be given:

- The reference note produced by a human expert
- The candidate note produced by the model

Your goal is to determine whether the candidate summary is faithful to the reference note, using the following evaluation criteria:

1. **Accuracy of Medical Facts**: All medical conditions, diagnoses, treatments, and test results must be correctly stated and consistent with the source text.
2. **Completeness of Critical Information**: The summary should include all vital information necessary for follow-up care (e.g., key symptoms, diagnoses, procedures, outcomes).
3. **Absence of Hallucinations**: The summary should not introduce any information that is not present in the original discharge note.
4. **Clarity and Non-Misleading Content**: The summary should be clear, free of ambiguity, and should not distort or misrepresent any facts.

Instructions:

- Compare the candidate summary to the reference summary.
- Provide a numerical rating of the candidate summary's faithfulness on a scale from 1 (completely unfaithful) to 10 (fully faithful).
- Respond only with the numerical rating without any explanation or context.

Reference Note:

\{reference\}

Candidate Note:

\{prediction\}

Output Format:

\[Numerical faithfulness rating only, from 1 to 10\]

</Box>
</Typography>
